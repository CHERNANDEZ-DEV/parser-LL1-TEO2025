# Preguntas y respuestas para defensa - Parser LL(1)

## Preguntas b√°sicas (Fundamentos)

### **P1: ¬øQu√© significa LL(1) y por qu√© eligieron esta t√©cnica para su proyecto?**

**Respuesta:**
LL(1) significa:
- **L** (Left-to-right): Leemos los tokens de izquierda a derecha
- **L** (Leftmost derivation): Construimos derivaciones por la izquierda
- **(1)**: Usamos 1 token de lookahead para tomar decisiones

Elegimos LL(1) porque:
1. **Simplicidad de implementaci√≥n**: Es m√°s directo implementar que LR(1)
2. **Detecci√≥n temprana de errores**: Los errores se detectan tan pronto como aparecen
3. **Recuperaci√≥n de errores predecible**: Podemos implementar estrategias de recuperaci√≥n claras
4. **Comprensi√≥n did√°ctica**: Es m√°s f√°cil entender el flujo del algoritmo
5. **Eficiencia**: O(n) tiempo lineal, sin backtracking

---

### **P2: Explique las fases de su compilador y c√≥mo se relacionan entre s√≠.**

**Respuesta:**
Nuestro compilador tiene 4 fases principales:

1. **An√°lisis L√©xico (lexer/)**:
   - **Input**: C√≥digo fuente (string)
   - **Output**: Lista de tokens
   - **Funci√≥n**: Convierte caracteres en unidades l√©xicas (palabras clave, operadores, identificadores)

2. **An√°lisis Sint√°ctico (parser/)**:
   - **Input**: Lista de tokens
   - **Output**: AST + lista de errores sint√°cticos
   - **Funci√≥n**: Verifica estructura gramatical y construye √°rbol de sintaxis

3. **An√°lisis Sem√°ntico (sema/)**:
   - **Input**: AST
   - **Output**: Lista de errores sem√°nticos
   - **Funci√≥n**: Verifica tipos, declaraciones, √°mbitos

4. **Pretty Printer (ast/pretty.py)**:
   - **Input**: AST
   - **Output**: Representaci√≥n textual del √°rbol
   - **Funci√≥n**: Visualizaci√≥n para debugging y an√°lisis

**Flujo de datos:**
```
C√≥digo fuente ‚Üí [Lexer] ‚Üí Tokens ‚Üí [Parser] ‚Üí AST ‚Üí [Semantic] ‚Üí AST validado
                                      ‚Üì
                              [Pretty Printer] ‚Üí Visualizaci√≥n
```

---

### **P3: ¬øC√≥mo maneja su parser la precedencia de operadores?**

**Respuesta:**
Usamos la t√©cnica de **precedence climbing** con una tabla de precedencia:

```python
_PREC = [
    {TokenKind.OROR},           # Precedencia 0 (m√°s baja)
    {TokenKind.ANDAND},         # Precedencia 1
    {TokenKind.EQEQ, TokenKind.NEQ},     # Precedencia 2
    {TokenKind.LT, TokenKind.LE, TokenKind.GT, TokenKind.GE}, # Precedencia 3
    {TokenKind.PLUS, TokenKind.MINUS},   # Precedencia 4
    {TokenKind.STAR, TokenKind.SLASH, TokenKind.PERCENT},     # Precedencia 5 (m√°s alta)
]
```

**Algoritmo:**
```python
def parse_bin_level(level: int) -> Expr:
    if level >= len(_PREC):
        return parse_unary()  # Base case
    left = parse_bin_level(level + 1)  # Operadores de mayor precedencia primero
    while tokens[i].kind in _PREC[level]:
        op_tok = tokens[i]
        right = parse_bin_level(level + 1)  # Recursi√≥n para mantener precedencia
        left = Binary(_BIN_OP_STR[op_tok.kind], left, right)
    return left
```

**Ejemplo**: `2 + 3 * 4` se parsea como `2 + (3 * 4)` porque `*` (nivel 5) tiene mayor precedencia que `+` (nivel 4).

---

## Preguntas intermedias (Implementaci√≥n)

### **P4: ¬øC√≥mo implementaron la recuperaci√≥n de errores en su parser?**

**Respuesta:**
Implementamos recuperaci√≥n de errores usando **panic mode recovery**:

1. **Detecci√≥n**: Cuando `expect()` falla, lanzamos `ParseError`
2. **Sincronizaci√≥n**: Usamos `synchronize()` para buscar tokens de sincronizaci√≥n
3. **Continuaci√≥n**: El parser contin√∫a desde el punto de sincronizaci√≥n

```python
def expect(kind: TokenKind, msg: str):
    if tokens[i].kind == kind:
        i += 1
        return tokens[i-1]
    t = tokens[i]
    report(errors, t.line, t.col, msg + f"; se encontr√≥ '{t.lexeme}'")
    raise ParseError()  # ‚Üê Detecci√≥n

def synchronize(sync_kinds: set[TokenKind]):
    while tokens[i].kind not in sync_kinds and tokens[i].kind != TokenKind.EOF:
        i += 1  # ‚Üê Sincronizaci√≥n

# Uso en declaraciones:
try:
    ts = parse_type()
except ParseError:
    synchronize({TokenKind.SEMI, TokenKind.RBRACE})  # ‚Üê Recuperaci√≥n
    match(TokenKind.SEMI)
    return None
```

**Ventajas:**
- Reporta m√∫ltiples errores en una sola pasada
- No se detiene en el primer error
- Tokens de sincronizaci√≥n bien elegidos (`;`, `}`)

---

### **P5: Explique c√≥mo funciona su tabla de s√≠mbolos y el manejo de √°mbitos.**

**Respuesta:**
Implementamos una **pila de √°mbitos** para manejar la visibilidad de s√≠mbolos:

```python
# Stack de scopes
_scope_stack: List[Dict[str, Symbol]] = []

def enter_scope():
    _scope_stack.append({})  # Nuevo √°mbito

def leave_scope():
    if _scope_stack:
        _scope_stack.pop()  # Salir del √°mbito actual

def declare(symbol: Symbol, errors: List[str], line: int, col: int):
    current_scope = _scope_stack[-1]  # √Åmbito m√°s interno
    if name in current_scope:
        errors.append(f"'{name}' ya declarado en este √°mbito")
    else:
        current_scope[name] = symbol

def lookup(name: str) -> Optional[Symbol]:
    # Buscar desde el √°mbito m√°s interno hacia afuera
    for scope in reversed(_scope_stack):
        if name in scope:
            return scope[name]
    return None  # No encontrado
```

**Ejemplo de uso:**
```c
int global_var = 10;    // √Åmbito global
int func(int param) {   // Nuevo √°mbito (funci√≥n)
    int local = 5;      // Variable local
    if (param > 0) {    // Nuevo √°mbito (if)
        int nested = 3; // Variable anidada
        return local + nested;  // ‚úÖ Ambas visibles
    }
    return nested;      // ‚ùå Error: 'nested' no visible
}
```

---

### **P6: ¬øC√≥mo verifican la compatibilidad de tipos en las expresiones?**

**Respuesta:**
Implementamos verificaci√≥n de tipos en el an√°lisis sem√°ntico:

```python
def is_integer(t: TypeSpec | ArrayType | None) -> bool:
    return isinstance(t, TypeSpec) and t.ptr_depth == 0 and t.base in {"int", "char"}

def is_arith(t: TypeSpec | ArrayType | None) -> bool:
    return isinstance(t, TypeSpec) and t.ptr_depth == 0 and t.base in {"int", "char", "float", "double"}

def assignable(dst: TypeSpec | ArrayType, src: TypeSpec | ArrayType) -> bool:
    # Tipos exactamente iguales
    if dst.base == src.base and dst.ptr_depth == src.ptr_depth:
        return True
    
    # Conversi√≥n entre tipos num√©ricos
    num = {"char", "int", "float", "double"}
    if dst.ptr_depth == 0 and src.ptr_depth == 0 and dst.base in num and src.base in num:
        return True
    
    # Conversi√≥n entre punteros
    if dst.ptr_depth > 0 and src.ptr_depth > 0:
        return True
    
    return False
```

**Verificaciones espec√≠ficas:**
1. **Operaciones aritm√©ticas**: Ambos operandos deben ser tipos aritm√©ticos
2. **Operaciones l√≥gicas**: Operandos deben ser enteros o punteros
3. **Asignaciones**: Tipos deben ser asignables seg√∫n `assignable()`
4. **√çndices de arrays**: El √≠ndice debe ser entero
5. **Llamadas a funci√≥n**: N√∫mero y tipos de par√°metros deben coincidir

---

## Preguntas avanzadas (Dise√±o y Optimizaci√≥n)

### **P7: ¬øQu√© limitaciones tiene su gram√°tica LL(1) y c√≥mo las resolvieron?**

**Respuesta:**

**Limitaciones principales:**

1. **Recursi√≥n izquierda**: No permitida en LL(1)
2. **Factorizaci√≥n izquierda**: Necesaria para prefijos comunes  
3. **Ambig√ºedades**: Como el "dangling else"

**Soluciones implementadas:**

### **1. Recursi√≥n Izquierda - Soluci√≥n con Precedence Climbing:**

**El problema cl√°sico:**
```
‚ùå Gram√°tica con recursi√≥n izquierda (NO funciona en LL(1)):
Expresi√≥n ‚Üí Expresi√≥n '+' T√©rmino    // Bucle infinito
Expresi√≥n ‚Üí Expresi√≥n '-' T√©rmino    // Bucle infinito  
Expresi√≥n ‚Üí T√©rmino                  // Caso base
```

**Transformaci√≥n cl√°sica (te√≥rica):**
```
‚úÖ Transformaci√≥n est√°ndar:
Expresi√≥n ‚Üí T√©rmino RestExpresi√≥n
RestExpresi√≥n ‚Üí '+' T√©rmino RestExpresi√≥n | '-' T√©rmino RestExpresi√≥n | Œµ
```

**Nuestra soluci√≥n superior - Precedence Climbing:**
```python
# parser/parser.py - l√≠neas 207-215
def parse_bin_level(level: int) -> Expr:
    if level >= len(_PREC):
        return parse_unary()  # Base case - no recursi√≥n izquierda
    
    left = parse_bin_level(level + 1)  # Recursi√≥n hacia ADELANTE (mayor precedencia)
    
    while tokens[i].kind in _PREC[level]:  # ITERACI√ìN en lugar de recursi√≥n
        op_tok = tokens[i]; i_inc()
        right = parse_bin_level(level + 1)  # Recursi√≥n hacia ADELANTE
        left = Binary(_BIN_OP_STR[op_tok.kind], left, right)  # Acumulaci√≥n
    return left
```

**Tabla de precedencia:**
```python
# parser/parser.py - l√≠neas 11-18  
_PREC = [
    {TokenKind.OROR},           # Precedencia 0 (m√°s baja)
    {TokenKind.ANDAND},         # Precedencia 1
    {TokenKind.EQEQ, TokenKind.NEQ},     # Precedencia 2
    {TokenKind.LT, TokenKind.LE, TokenKind.GT, TokenKind.GE}, # Precedencia 3
    {TokenKind.PLUS, TokenKind.MINUS},   # Precedencia 4
    {TokenKind.STAR, TokenKind.SLASH, TokenKind.PERCENT},     # Precedencia 5 (m√°s alta)
]
```

**Ejemplo de traza para `2 + 3 + 4`:**
```
parse_bin_level(4)  // Nivel de + y -
‚îú‚îÄ‚îÄ left = parse_bin_level(5) ‚Üí Number(2)  // Sin recursi√≥n izquierda
‚îú‚îÄ‚îÄ while PLUS in _PREC[4]:
‚îÇ   ‚îú‚îÄ‚îÄ right = parse_bin_level(5) ‚Üí Number(3)  
‚îÇ   ‚îî‚îÄ‚îÄ left = Binary('+', Number(2), Number(3))  // Acumulaci√≥n
‚îî‚îÄ‚îÄ while PLUS in _PREC[4]:
    ‚îú‚îÄ‚îÄ right = parse_bin_level(5) ‚Üí Number(4)
    ‚îî‚îÄ‚îÄ left = Binary('+', Binary('+', 2, 3), Number(4))  // Asociatividad izquierda correcta
```

**Ventajas de nuestra implementaci√≥n:**
- ‚úÖ **Una sola funci√≥n** maneja todos los operadores binarios
- ‚úÖ **Precedencia autom√°tica** basada en tabla
- ‚úÖ **Escalable**: Agregar operadores es trivial
- ‚úÖ **Eficiente**: O(n) sin backtracking
- ‚úÖ **Asociatividad correcta** sin recursi√≥n izquierda

### **2. Para el dangling else:** 
Regla impl√≠cita greedy matching - el `else` se asocia con el `if` m√°s cercano

### **3. Para factorizaci√≥n izquierda:** 
Reestructuramos reglas para eliminar prefijos comunes

**Gram√°ticas que NO podemos manejar:**
- Lenguajes que requieren contexto (LL(1) es libre de contexto)
- Construcciones que necesitan m√°s de 1 token lookahead
- Gram√°ticas inherentemente ambiguas

---

### **P8: Explique espec√≠ficamente c√≥mo resolvieron el problema de la recursi√≥n izquierda en las expresiones aritm√©ticas.**

**Respuesta:**

**El problema fundamental:**
La recursi√≥n izquierda causa **bucles infinitos** en parsers LL(1):

```python
# ‚ùå Esto NO funcionar√≠a:
def parse_expresion():
    left = parse_expresion()  # ‚Üê ¬°BUCLE INFINITO!
    if current_token == PLUS:
        consume(PLUS)
        right = parse_termino()
        return Binary('+', left, right)
    return left
```

**Nuestra soluci√≥n - Precedence Climbing Algorithm:**

**Paso 1**: Definimos tabla de precedencia (de menor a mayor):
```python
_PREC = [
    {TokenKind.OROR},           # 0: ||
    {TokenKind.ANDAND},         # 1: &&  
    {TokenKind.EQEQ, TokenKind.NEQ},     # 2: == !=
    {TokenKind.LT, TokenKind.LE, TokenKind.GT, TokenKind.GE}, # 3: < <= > >=
    {TokenKind.PLUS, TokenKind.MINUS},   # 4: + -
    {TokenKind.STAR, TokenKind.SLASH, TokenKind.PERCENT},     # 5: * / %
]
```

**Paso 2**: Algoritmo que evita recursi√≥n izquierda:
```python
def parse_bin_level(level: int) -> Expr:
    # Base case: nivel m√°s alto ‚Üí operadores unarios
    if level >= len(_PREC):
        return parse_unary()
    
    # ‚úÖ CLAVE: Empezar con operadores de MAYOR precedencia
    left = parse_bin_level(level + 1)  # No es recursi√≥n izquierda
    
    # ‚úÖ ITERACI√ìN en lugar de recursi√≥n para mismo nivel
    while tokens[i].kind in _PREC[level]:
        op_tok = tokens[i]; i_inc()
        right = parse_bin_level(level + 1)  # Otra vez mayor precedencia
        left = Binary(_BIN_OP_STR[op_tok.kind], left, right)
    
    return left
```

**Ejemplo paso a paso con `2 + 3 * 4`:**

```
parse_bin_level(4)  // Nivel de + y -
‚îú‚îÄ‚îÄ left = parse_bin_level(5)  // Nivel de * / %
‚îÇ   ‚îú‚îÄ‚îÄ left = parse_bin_level(6)  // Base case
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ return parse_unary() ‚Üí Number(2)
‚îÇ   ‚îî‚îÄ‚îÄ while: no hay * o /, return Number(2)
‚îú‚îÄ‚îÄ while tokens[i] == PLUS:  // Encontr√≥ +
‚îÇ   ‚îú‚îÄ‚îÄ right = parse_bin_level(5)  // Nivel de * / %
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ left = parse_unary() ‚Üí Number(3)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ while tokens[i] == STAR:  // Encontr√≥ *
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ right = parse_unary() ‚Üí Number(4)  
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ left = Binary('*', Number(3), Number(4))
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ return Binary('*', Number(3), Number(4))
‚îÇ   ‚îî‚îÄ‚îÄ left = Binary('+', Number(2), Binary('*', Number(3), Number(4)))
‚îî‚îÄ‚îÄ return Binary('+', Number(2), Binary('*', Number(3), Number(4)))
```

**Resultado AST correcto:**
```
Binary('+')
‚îú‚îÄ‚îÄ Number(2)
‚îî‚îÄ‚îÄ Binary('*')
    ‚îú‚îÄ‚îÄ Number(3)  
    ‚îî‚îÄ‚îÄ Number(4)
```

**¬øPor qu√© NO hay recursi√≥n izquierda?**

1. **Nunca llamamos `parse_bin_level(level)`** - siempre `level + 1`
2. **Siempre avanzamos hacia mayor precedencia** - progreso garantizado  
3. **Usamos iteraci√≥n (`while`)** para operadores del mismo nivel
4. **El nivel eventualmente llega a `parse_unary()`** - caso base real

**Ventajas sobre transformaci√≥n cl√°sica:**
- ‚úÖ **M√°s simple**: Una funci√≥n vs m√∫ltiples reglas
- ‚úÖ **M√°s eficiente**: O(n) vs O(n log n)  
- ‚úÖ **M√°s mantenible**: Cambiar precedencia es editar una tabla
- ‚úÖ **M√°s legible**: El c√≥digo refleja la intenci√≥n

---

### **P9: ¬øC√≥mo extender√≠an su compilador para generar c√≥digo intermedio?**

**Respuesta:**
Para generar c√≥digo intermedio agregar√≠amos una nueva fase:

```python
# Nueva fase: Generaci√≥n de c√≥digo intermedio
def generate_ir(ast: Program) -> List[Instruction]:
    instructions = []
    temp_counter = 0
    
    def new_temp():
        nonlocal temp_counter
        temp_counter += 1
        return f"t{temp_counter}"
    
    def visit_binary(node: Binary) -> str:
        left_temp = visit_expr(node.left)
        right_temp = visit_expr(node.right)
        result_temp = new_temp()
        instructions.append(f"{result_temp} = {left_temp} {node.op} {right_temp}")
        return result_temp
    
    def visit_assign(node: Assign) -> str:
        right_temp = visit_expr(node.right)
        if isinstance(node.left, Var):
            instructions.append(f"{node.left.name} = {right_temp}")
        return right_temp
```

**Tipos de c√≥digo intermedio posibles:**
1. **C√≥digo de tres direcciones**: `t1 = a + b`
2. **Bytecode**: Instrucciones de m√°quina virtual
3. **SSA (Static Single Assignment)**: Cada variable se asigna una sola vez
4. **LLVM IR**: Para usar el backend de LLVM

**Ventajas del c√≥digo intermedio:**
- Independiente de la m√°quina target
- Facilita optimizaciones
- Permite m√∫ltiples backends
- Debugging m√°s claro

---

### **P10: ¬øC√≥mo optimizar√≠an el AST generado por su parser?**

**Respuesta:**
Implementar√≠amos optimizaciones en m√∫ltiples niveles:

**1. Optimizaciones en el AST:**

```python
def optimize_ast(node):
    # Constant folding
    if isinstance(node, Binary) and isinstance(node.left, Number) and isinstance(node.right, Number):
        if node.op == '+':
            return Number(node.left.value + node.right.value)
        elif node.op == '*':
            return Number(node.left.value * node.right.value)
    
    # Dead code elimination
    if isinstance(node, IfStmt) and isinstance(node.cond, Number):
        if node.cond.value != 0:
            return node.then  # Condici√≥n siempre verdadera
        elif node.els:
            return node.els   # Condici√≥n siempre falsa
        else:
            return None       # Eliminar if completo
    
    # Strength reduction
    if isinstance(node, Binary) and node.op == '*' and isinstance(node.right, Number):
        if node.right.value == 2:
            return Binary('+', node.left, node.left)  # x * 2 ‚Üí x + x
```

**2. Optimizaciones de control de flujo:**
- Eliminaci√≥n de saltos innecesarios
- Fusi√≥n de bloques b√°sicos consecutivos
- Eliminaci√≥n de c√≥digo unreachable

**3. Optimizaciones de expresiones:**
- Propagaci√≥n de constantes
- Eliminaci√≥n de subexpresiones comunes
- Reducci√≥n de fuerza (multiplicaci√≥n ‚Üí suma)

---

### **P12: ¬øC√≥mo manejar√≠an la concurrencia si quisieran paralelizar el compilador?**

**Respuesta:**

**An√°lisis de dependencias:**
```
C√≥digo fuente ‚Üí [Lexer] ‚Üí Tokens ‚Üí [Parser] ‚Üí AST ‚Üí [Semantic] ‚Üí AST validado
    ‚Üë              ‚Üë          ‚Üë         ‚Üë          ‚Üë
Secuencial    Secuencial  Secuencial  Paralelo   Paralelo
```

**Oportunidades de paralelizaci√≥n:**

1. **An√°lisis sem√°ntico por funciones**:
```python
def parallel_semantic_check(functions: List[FuncDecl]) -> List[str]:
    with ThreadPoolExecutor() as executor:
        futures = [executor.submit(check_function, func) for func in functions]
        errors = []
        for future in futures:
            errors.extend(future.result())
    return errors
```

2. **M√∫ltiples archivos fuente**:
```python
def compile_files(files: List[str]) -> Dict[str, AST]:
    with ProcessPoolExecutor() as executor:
        futures = {executor.submit(compile_single_file, f): f for f in files}
        results = {}
        for future in futures:
            filename = futures[future]
            results[filename] = future.result()
    return results
```

**Desaf√≠os de concurrencia:**
- **Tabla de s√≠mbolos compartida**: Requiere sincronizaci√≥n
- **Dependencias entre m√≥dulos**: L√≠mites a la paralelizaci√≥n
- **Orden de errores**: Puede cambiar con paralelizaci√≥n

**Soluciones:**
- **Lock-free data structures** para tabla de s√≠mbolos
- **Message passing** en lugar de memoria compartida
- **Fork-join pattern** para an√°lisis independientes

---

### **P13: ¬øC√≥mo implementar√≠an herramientas de desarrollo como autocompletado o refactoring?**

**Respuesta:**

**1. Language Server Protocol (LSP):**
```python
class LanguageServer:
    def __init__(self):
        self.symbol_table = SymbolTable()
        self.ast_cache = {}
    
    def on_text_changed(self, document_uri: str, text: str):
        # Reparse incrementalmente
        tokens = tokenize(text)
        ast, errors = parse(tokens)
        self.ast_cache[document_uri] = ast
        
        # An√°lisis sem√°ntico en background
        semantic_errors = check(ast)
        self.send_diagnostics(document_uri, errors + semantic_errors)
    
    def provide_completions(self, position: Position) -> List[CompletionItem]:
        # Usar tabla de s√≠mbolos para sugerir variables/funciones
        visible_symbols = self.symbol_table.get_visible_at(position)
        return [CompletionItem(sym.name, sym.type) for sym in visible_symbols]
```

**2. An√°lisis est√°tico avanzado:**
```python
def find_all_references(ast: Program, target_symbol: str) -> List[Position]:
    references = []
    
    class ReferenceVisitor:
        def visit_var(self, node: Var):
            if node.name == target_symbol:
                references.append(node.position)
    
    visitor = ReferenceVisitor()
    visitor.visit(ast)
    return references

def rename_symbol(ast: Program, old_name: str, new_name: str) -> Program:
    # AST transformation para renaming seguro
    transformer = RenameTransformer(old_name, new_name)
    return transformer.transform(ast)
```

**3. Herramientas espec√≠ficas:**
- **Syntax highlighting**: Basado en tokens del lexer
- **Error squiggles**: Posiciones de errores del parser/semantic analyzer
- **Go to definition**: Usando tabla de s√≠mbolos
- **Hover information**: Informaci√≥n de tipos del an√°lisis sem√°ntico
- **Code formatting**: Basado en el pretty printer

---

## Preguntas de casos espec√≠ficos

### **P14: Muestren c√≥mo su parser maneja este c√≥digo con errores: `int x = y + 1; int y = 5;`**

**Respuesta:**

**Fase 1 - An√°lisis L√©xico**: ‚úÖ Sin problemas
```
[KW_INT] [IDENT:"x"] [ASSIGN] [IDENT:"y"] [PLUS] [NUMBER:1] [SEMI] 
[KW_INT] [IDENT:"y"] [ASSIGN] [NUMBER:5] [SEMI]
```

**Fase 2 - An√°lisis Sint√°ctico**: ‚úÖ AST v√°lido
```
Program
‚îú‚îÄ‚îÄ VarDecl(type=int, name="x", init=Binary(+, Var("y"), Number(1)))
‚îî‚îÄ‚îÄ VarDecl(type=int, name="y", init=Number(5))
```

**Fase 3 - An√°lisis Sem√°ntico**: ‚ùå Error sem√°ntico
```python
# En check_var_decl():
for vi in d.inits:
    if vi.init:
        init_type = type_of_expr(vi.init)  # Eval√∫a y + 1
        # En type_of_expr para Binary:
        if isinstance(e, Binary):
            left_type = type_of_expr(e.left)  # type_of_expr(Var("y"))
            # En type_of_expr para Var:
            if isinstance(e, Var):
                sym = lookup(e.name)  # lookup("y") ‚Üí None
                if sym is None:
                    errors.append(f"'{e.name}' no declarada")  # ‚Üê ERROR AQU√ç
```

**Output del compilador:**
```
Error en l√≠nea 1, columna 9: 'y' no declarada
Program
‚îú‚îÄ‚îÄ VarDecl(type=int, name="x", init=Binary(+, Var("y"), Number(1)))
‚îî‚îÄ‚îÄ VarDecl(type=int, name="y", init=Number(5))
```

**¬øPor qu√© sucede esto?**
- Las declaraciones se procesan secuencialmente
- `y` no existe cuando se eval√∫a `x = y + 1`
- Nuestro compilador no hace forward declarations autom√°ticas

---

### **P15: ¬øC√≥mo maneja su parser la ambig√ºedad del "dangling else"?**

**Respuesta:**

**El problema:**
```c
if (a > 0)
    if (b > 0)
        printf("ambos positivos");
else  // ¬øA cu√°l if pertenece?
    printf("a no es positivo");
```

**Posibles interpretaciones:**
```c
// Interpretaci√≥n 1:
if (a > 0) {
    if (b > 0) {
        printf("ambos positivos");
    } else {
        printf("a no es positivo");  // ‚Üê Incorrecto sem√°nticamente
    }
}

// Interpretaci√≥n 2 (correcta):
if (a > 0) {
    if (b > 0) {
        printf("ambos positivos");
    }
} else {
    printf("a no es positivo");
}
```

**Soluci√≥n en nuestro parser:**
```python
def parse_stmt() -> Optional[Stmt]:
    if k == TokenKind.KW_IF:
        match(TokenKind.KW_IF)
        expect(TokenKind.LPAREN, "( tras if")
        cond = parse_expr()
        expect(TokenKind.RPAREN, ") tras condici√≥n")
        then = parse_stmt()  # ‚Üê Recursi√≥n que consume el else m√°s cercano
        els = None
        if match(TokenKind.KW_ELSE):  # ‚Üê Greedy matching
            els = parse_stmt()
        return IfStmt(cond, then, els)
```

**Regla aplicada**: **Greedy matching** - el `else` se asocia con el `if` m√°s cercano (m√°s interno).

**Resultado**: El parser siempre elige la Interpretaci√≥n 1, que es el comportamiento est√°ndar en C.

**Para forzar la Interpretaci√≥n 2**, el programador debe usar llaves:
```c
if (a > 0) {
    if (b > 0)
        printf("ambos positivos");
}
else
    printf("a no es positivo");
```

---

### **P16: Demuestren el parsing completo de esta funci√≥n recursiva:**

```c
int factorial(int n) {
    if (n <= 1)
        return 1;
    return n * factorial(n - 1);
}
```

**Respuesta:**

**Traza completa del parsing:**

**1. Entrada en parse_declaration():**
```
Token actual: KW_INT
‚Üì
parse_type() ‚Üí TypeSpec(base="int", ptr_depth=0)
Token actual: IDENT("factorial")
Token siguiente: LPAREN ‚Üí Es una funci√≥n
```

**2. Parsing de par√°metros:**
```
match(LPAREN) ‚úÖ
parse_type() ‚Üí TypeSpec(base="int", ptr_depth=0)  
Token: IDENT("n") ‚Üí Par√°metro: Param(type=int, name="n")
match(RPAREN) ‚úÖ
```

**3. Parsing del cuerpo (parse_compound()):**
```
match(LBRACE) ‚úÖ
Tokens en el bloque: KW_IF, KW_RETURN, KW_RETURN, RBRACE
```

**4. Primera sentencia (IfStmt):**
```
parse_stmt() ‚Üí KW_IF detectado
‚îú‚îÄ‚îÄ parse_expr() para condici√≥n: "n <= 1"
‚îÇ   ‚îî‚îÄ‚îÄ parse_assign() ‚Üí parse_bin_level(0)
‚îÇ       ‚îî‚îÄ‚îÄ Binary(op="<=", left=Var("n"), right=Number(1))
‚îú‚îÄ‚îÄ parse_stmt() para then: "return 1"
‚îÇ   ‚îî‚îÄ‚îÄ ReturnStmt(expr=Number(1))
‚îî‚îÄ‚îÄ else: None (no hay else)
```

**5. Segunda sentencia (ReturnStmt):**
```
parse_stmt() ‚Üí KW_RETURN detectado
parse_expr(): "n * factorial(n - 1)"
‚îú‚îÄ‚îÄ parse_assign() ‚Üí parse_bin_level(0)
‚îú‚îÄ‚îÄ Izquierda: parse_bin_level(1) ‚Üí ... ‚Üí Var("n")
‚îú‚îÄ‚îÄ Operador: STAR (precedencia 5)  
‚îî‚îÄ‚îÄ Derecha: parse_bin_level(6) ‚Üí parse_postfix()
    ‚îî‚îÄ‚îÄ Call(callee=Var("factorial"), args=[Binary("-", Var("n"), Number(1))])
```

**6. AST resultante:**
```
FuncDecl(
    ret_type=TypeSpec(base="int"),
    name="factorial", 
    params=[Param(type=TypeSpec(base="int"), name="n")],
    body=Block([
        IfStmt(
            cond=Binary(op="<=", left=Var("n"), right=Number(1)),
            then=ReturnStmt(expr=Number(1)),
            els=None
        ),
        ReturnStmt(
            expr=Binary(
                op="*",
                left=Var("n"),
                right=Call(
                    callee=Var("factorial"),
                    args=[Binary(op="-", left=Var("n"), right=Number(1))]
                )
            )
        )
    ])
)
```

**Puntos clave demostrados:**
- ‚úÖ Recursi√≥n mutua entre `parse_stmt()` y `parse_compound()`
- ‚úÖ Precedencia correcta: `*` antes que `-` en la expresi√≥n  
- ‚úÖ Llamada recursiva parseada como `Call` node
- ‚úÖ Estructura anidada del AST reflejando la gram√°tica

---

## Preguntas trampa

### **PT1: "Su parser es LL(1), ¬øverdad? Entonces deber√≠a poder parsear cualquier gram√°tica libre de contexto..."**

**üö´ TRAMPA**: LL(1) NO puede parsear cualquier gram√°tica libre de contexto.

**‚úÖ RESPUESTA CORRECTA:**
"No, eso es incorrecto. LL(1) es un **subconjunto** de las gram√°ticas libres de contexto. Espec√≠ficamente:

- **LL(1) ‚äÇ LR(1) ‚äÇ Gram√°ticas Libres de Contexto**
- LL(1) no puede manejar:
  - Recursi√≥n izquierda: `A ‚Üí A Œ±`
  - Ambig√ºedades: m√∫ltiples derivaciones para la misma entrada
  - Gram√°ticas que requieren m√°s de 1 token lookahead
  
**Ejemplo de gram√°tica libre de contexto que NO es LL(1):**
```
S ‚Üí A a | B b
A ‚Üí Œµ  
B ‚Üí Œµ
```
Con entrada `a`, no sabemos si elegir la primera o segunda producci√≥n hasta ver el `a`."

---

### **PT2: "Como usan precedence climbing, su parser NO es realmente LL(1), ¬øcierto?"**

**üö´ TRAMPA**: Confundir algoritmo de implementaci√≥n con clasificaci√≥n te√≥rica.

**‚úÖ RESPUESTA CORRECTA:**
"Eso es incorrecto. Precedence climbing es una **t√©cnica de implementaci√≥n** que sigue siendo LL(1):

1. **Sigue siendo LL(1) porque:**
   - Lee de izquierda a derecha ‚úì
   - Usa derivaciones por la izquierda ‚úì  
   - Necesita solo 1 token lookahead ‚úì
   - No hace backtracking ‚úì

2. **Precedence climbing es equivalente a:**
   ```
   // Gram√°tica LL(1) equivalente (transformada):
   Expr ‚Üí Term (('+' | '-') Term)*
   Term ‚Üí Factor (('*' | '/') Factor)*
   Factor ‚Üí Number | '(' Expr ')'
   ```

3. **Es solo una optimizaci√≥n** que evita crear m√∫ltiples funciones de parsing para cada nivel de precedencia."

---

### **PT3: "Si su lexer encuentra un identificador como 'if123', ¬ølo tokeniza como IF seguido de 123?"**

**üö´ TRAMPA**: Confundir reglas de tokenizaci√≥n con reconocimiento de palabras clave.

**‚úÖ RESPUESTA CORRECTA:**
"No, eso ser√≠a incorrecto. Nuestro lexer usa **maximal munch** (coincidencia m√°xima):

```python
# En lexer/lexer.py - as√≠ funciona realmente:
def tokenize_identifier_or_keyword(text, pos):
    start = pos
    while pos < len(text) and (text[pos].isalnum() or text[pos] == '_'):
        pos += 1  # Consume TODOS los caracteres v√°lidos
    
    lexeme = text[start:pos]  # 'if123' completo
    
    # Verificar si es palabra clave DESPU√âS
    if lexeme in KEYWORDS:  # 'if123' NO est√° en KEYWORDS
        return Token(KEYWORDS[lexeme], lexeme, ...)
    else:
        return Token(TokenKind.IDENT, lexeme, ...)  # Es un identificador
```

**Resultado:** `'if123'` ‚Üí `Token(IDENT, 'if123')`, no `Token(IF) + Token(NUMBER)`"

---

### **PT4: "Su an√°lisis sem√°ntico detecta que 'x' no est√° declarada. ¬øPor qu√© no simplemente la declaran autom√°ticamente como 'auto'?"**

**üö´ TRAMPA**: Confundir lenguajes con diferentes reglas de declaraci√≥n.

**‚úÖ RESPUESTA CORRECTA:**
"Esa ser√≠a una decisi√≥n de dise√±o incorrecta para un compilador de C:

1. **C requiere declaraciones expl√≠citas** - es parte de la especificaci√≥n del lenguaje
2. **Declaraci√≥n autom√°tica introducir√≠a bugs silenciosos:**
   ```c
   int main() {
       int contador = 0;
       // ... 100 l√≠neas despu√©s
       contadro = 5;  // Typo - crear√≠a variable nueva en lugar de error
   }
   ```
3. **Nuestro rol es implementar C correctamente**, no inventar un nuevo lenguaje
4. **La detecci√≥n de errores es una caracter√≠stica**, no un bug a arreglar"

---

### **PT5: "Veo que su parser puede recuperarse de errores. ¬øSignifica que pueden compilar c√≥digo con errores sint√°cticos?"**

**üö´ TRAMPA**: Confundir recuperaci√≥n de errores con compilaci√≥n exitosa.

**‚úÖ RESPUESTA CORRECTA:**
"No, la recuperaci√≥n de errores NO significa compilaci√≥n exitosa:

**Prop√≥sito de la recuperaci√≥n:**
1. **Reportar m√∫ltiples errores** en una sola pasada
2. **Continuar el an√°lisis** para encontrar m√°s problemas  
3. **Mejor experiencia de desarrollo** - ver todos los errores juntos

**Lo que NO hacemos:**
- ‚ùå Generar c√≥digo ejecutable con errores
- ‚ùå Ignorar errores sint√°cticos
- ‚ùå 'Adivinar' la intenci√≥n del programador

**Nuestro comportamiento:**
```python
ast, parse_errs = parse(tokens)
sema_errs = check(ast)
errs = parse_errs + sema_errs
if errs:
    print("\\n".join(errs), file=sys.stderr)  # ‚Üê Reportar errores
    # NO generar c√≥digo si hay errores
```"

---

### **PT6: "Su tabla de s√≠mbolos usa una pila. ¬øNo ser√≠a m√°s eficiente usar un hash table plano?"**

**üö´ TRAMPA**: Confundir eficiencia con correcci√≥n sem√°ntica.

**‚úÖ RESPUESTA CORRECTA:**
"No, un hash table plano ser√≠a **funcionalmente incorrecto** para manejar √°mbitos:

**El problema con hash table plano:**
```c
int x = 10;        // x = 10 globalmente
void func() {
    int x = 5;     // ¬øC√≥mo distinguir entre las dos 'x'?
    printf("%d", x); // Debe imprimir 5, no 10
}
```

**Por qu√© necesitamos pila de √°mbitos:**
1. **Scoping correcto**: Variables locales ocultan globales
2. **Gesti√≥n de memoria**: Variables salen de √°mbito autom√°ticamente  
3. **An√°lisis de visibilidad**: `lookup()` busca desde el √°mbito m√°s interno

**Nuestra implementaci√≥n:**
```python
_scope_stack = [
    {'x': Symbol(type=int, value=10)},  # √Åmbito global
    {'x': Symbol(type=int, value=5)}    # √Åmbito local (oculta global)
]
```

**Eficiencia real:** O(d) donde d = profundidad de anidamiento (t√≠picamente < 10)"

---

### **PT7: "Su AST tiene nodos como 'Binary' y 'Unary'. ¬øNo deber√≠an ser m√°s espec√≠ficos como 'Addition' y 'Multiplication'?"**

**üö´ TRAMPA**: Sobre-especializaci√≥n innecesaria del AST.

**‚úÖ RESPUESTA CORRECTA:**
"No, nuestro dise√±o es **intencionalmente gen√©rico** y superior:

**Ventajas de nodos gen√©ricos:**
```python
@dataclass
class Binary:
    op: str      # '+', '-', '*', '/', '<', '==', etc.
    left: Expr
    right: Expr
```

1. **Extensibilidad**: Agregar operadores no requiere nuevos nodos
2. **Consistencia**: Mismo patr√≥n para todos los operadores binarios
3. **Simplicidad**: Menos tipos de nodos que mantener
4. **Polimorfismo**: Mismo c√≥digo para procesar diferentes operadores

**Si fu√©ramos espec√≠ficos necesitar√≠amos:**
```python
class Addition, class Subtraction, class Multiplication, 
class Division, class LessThan, class GreaterThan, class Equal...
# ¬°15+ clases diferentes!
```

**Nuestro enfoque:**
- ‚úÖ **Un nodo gen√©rico** con campo discriminante (`op`)
- ‚úÖ **F√°cil extensi√≥n** para nuevos operadores  
- ‚úÖ **Pattern matching** simple en el an√°lisis sem√°ntico"

---

### **PT8: "He visto que llaman a 'parse_expr()' recursivamente. ¬øNo es esto recursi√≥n izquierda?"**

**üö´ TRAMPA**: Confundir recursi√≥n en implementaci√≥n con recursi√≥n izquierda en gram√°tica.

**‚úÖ RESPUESTA CORRECTA:**
"No, hay una diferencia fundamental:

**Recursi√≥n izquierda (problem√°tica):**
```
A ‚Üí A Œ±  // La regla empieza con el mismo no-terminal
```

**Recursi√≥n mutua (correcta):**
```python
def parse_primary():
    if match(LPAREN):
        expr = parse_expr()  # ‚Üê Recursi√≥n mutua, NO izquierda
        expect(RPAREN)
        return expr
```

**¬øPor qu√© NO es recursi√≥n izquierda?**

1. **Progreso garantizado**: `match(LPAREN)` consume un token ANTES de la recursi√≥n
2. **Caso base claro**: `LPAREN` debe existir para recurrir
3. **Terminaci√≥n**: Eventualmente se agotan los par√©ntesis

**Recursi√≥n izquierda ser√≠a:**
```python
def parse_expr():
    left = parse_expr()  # ‚Üê ¬°BUCLE INFINITO! No consume tokens
    # ...
```

**La clave:** Siempre consumimos tokens o avanzamos el estado antes de recurrir."

---

### **PT9: "Si su parser es LL(1), ¬øpor qu√© necesitan una tabla de precedencia? ¬øNo deber√≠a estar en la gram√°tica?"**

**üö´ TRAMPA**: Confundir implementaci√≥n optimizada con teor√≠a pura.

**‚úÖ RESPUESTA CORRECTA:**
"Excelente pregunta. La precedencia **EST√Å** en la gram√°tica, pero impl√≠citamente:

**Gram√°tica te√≥rica equivalente (que generar√≠amos):**
```
Expr ‚Üí OrExpr
OrExpr ‚Üí AndExpr ('||' AndExpr)*
AndExpr ‚Üí EqExpr ('&&' EqExpr)*  
EqExpr ‚Üí RelExpr (('==' | '!=') RelExpr)*
RelExpr ‚Üí AddExpr (('<' | '<=' | '>' | '>=') AddExpr)*
AddExpr ‚Üí MulExpr (('+' | '-') MulExpr)*
MulExpr ‚Üí UnaryExpr (('*' | '/' | '%') UnaryExpr)*
```

**Nuestra tabla ES esta gram√°tica compactada:**
```python
_PREC = [
    {TokenKind.OROR},     # OrExpr level
    {TokenKind.ANDAND},   # AndExpr level  
    {TokenKind.EQEQ, TokenKind.NEQ},  # EqExpr level
    # ... etc
]
```

**Ventajas de nuestra implementaci√≥n:**
- ‚úÖ **Misma sem√°ntica** que la gram√°tica expl√≠cita
- ‚úÖ **M√°s concisa**: 6 l√≠neas vs 14 reglas
- ‚úÖ **M√°s mantenible**: Cambiar precedencia = editar tabla
- ‚úÖ **Mismo comportamiento LL(1)**: 1 token lookahead, no backtracking"

---

### **PT10: "Su lexer ignora comentarios. ¬øNo deber√≠an preservarlos para herramientas como documentaci√≥n autom√°tica?"**

**üö´ TRAMPA**: Confundir compilador con herramientas de an√°lisis de c√≥digo.

**‚úÖ RESPUESTA CORRECTA:**
"Depende del **prop√≥sito** de la herramienta:

**Para un compilador (nuestro caso):**
- ‚úÖ **Ignorar comentarios es correcto** - no afectan la sem√°ntica del programa
- ‚úÖ **Simplifica el parser** - no necesita manejar comentarios en gram√°tica
- ‚úÖ **Est√°ndar en compiladores** - GCC, Clang hacen lo mismo

**Para herramientas de an√°lisis (diferente prop√≥sito):**
```python
# Se podr√≠a extender para preservar comentarios:
@dataclass  
class CommentToken:
    text: str
    line: int
    is_doc_comment: bool  # /** ... */ vs /* ... */

def tokenize_with_comments(source):
    # Preservar comentarios como tokens especiales
    pass
```

**Separaci√≥n de responsabilidades:**
- **Compilador**: Generar c√≥digo ejecutable (ignora comentarios)
- **Documentador**: Extraer documentaci√≥n (preserva comentarios)  
- **Formatter**: Preservar estilo (mantiene comentarios y whitespace)

**Nuestro enfoque es correcto para el prop√≥sito declarado.**"

---
